{"cells":[{"cell_type":"code","source":["#Carga de bibliotecas\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('operaciones_basicas').getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dcb07045-5e14-42f1-8971-c7d242065ae0"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Ejemplo básico con foreach()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c514ec28-1291-4d9e-bebb-dfe4bb249740"}}},{"cell_type":"code","source":["%scala\n\n/*Definiendo un RDD usando scala*/\nval rdd = spark.sparkContext.parallelize(Seq(5,10,15,20)) \n\n/* Creando una nueva variable */\nval ACC = spark.sparkContext.longAccumulator(\"Acumulador\")\n\n/* Foreach, su única función es sumar cada uno de los elementos del RDD y almacenar el resultado en la variable ACC*/\nrdd.foreach(f => {ACC.add(f)})\n\n/* Se imprime el resultado */\nprintln(\"Total del acumulador: \" + ACC.value)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f32b352e-b3ff-4eef-b3fe-3d09b4b37827"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Total del acumulador: 50\nrdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[48] at parallelize at command-995966193448851:3\nACC: org.apache.spark.util.LongAccumulator = LongAccumulator(id: 996, name: Some(Acumulador), value: 50)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Total del acumulador: 50\nrdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[48] at parallelize at command-995966193448851:3\nACC: org.apache.spark.util.LongAccumulator = LongAccumulator(id: 996, name: Some(Acumulador), value: 50)\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Ejemplo 2"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"387dcd71-68ef-4d3a-8ac9-94fcb9fcf309"}}},{"cell_type":"code","source":["%scala\n/*Definiendo un diccionario en scala*/\nval data = Seq((\"Dogs\",100), (\"Cats\",50),(\"Lions\",10),(\"Monkeys\",30))\n\n/* Convirtiendo la lista a DataFrame */\nval df = spark.createDataFrame(data).toDF(\"Animal\",\"Population\")\n\n/* Pasando un foreach */\ndf.foreach(f=> println(f))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"814ab833-62d5-40a8-bab5-698f34af60cb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"Animal","type":"string","nullable":true,"metadata":{}},{"name":"Population","type":"integer","nullable":false,"metadata":{}}]},"tableIdentifier":null}],"data":"<div class=\"ansiout\">data: Seq[(String, Int)] = List((Dogs,100), (Cats,50), (Lions,10), (Monkeys,30))\ndf: org.apache.spark.sql.DataFrame = [Animal: string, Population: int]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">data: Seq[(String, Int)] = List((Dogs,100), (Cats,50), (Lions,10), (Monkeys,30))\ndf: org.apache.spark.sql.DataFrame = [Animal: string, Population: int]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n/* Creando una nueva variable */\nval longAcc = spark.sparkContext.longAccumulator(\"Acumulador\")\n\n/* For each, va a recorrer internamente cada elemento, y sumará lo que contiene la columna \"Population\" */\ndf.foreach(f=> {longAcc.add(f.getInt(1))})\n\n/* Se imprime el resultado */\nprintln(\"Accumulator value:\"+longAcc.value)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f2a681fd-3bfe-491a-a379-261ef6a3dea3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Accumulator value:190\nlongAcc: org.apache.spark.util.LongAccumulator = LongAccumulator(id: 1058, name: Some(Acumulador), value: 190)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accumulator value:190\nlongAcc: org.apache.spark.util.LongAccumulator = LongAccumulator(id: 1058, name: Some(Acumulador), value: 190)\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"operaciones_basicas","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2078546801909618}},"nbformat":4,"nbformat_minor":0}
