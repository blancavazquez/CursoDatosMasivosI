{"cells":[{"cell_type":"markdown","source":["## Analizando la evaluación Lazy de Spark\n\nEl objetivo de esta libreta es analizar y comprender la evaluación Lazy que realiza Spark. A través de algunos escenarios revisaremos en qué consiste y visualizaremos el DAG (Diagrama Acíclico Dirigido)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ef6faa8c-6f39-4ce2-949f-bf866df3075f"}}},{"cell_type":"code","source":["#Creado dataFrame\ndf_fifa = spark.read.csv('/FileStore/tables/players_20.csv', header = True, inferSchema = True)\n\ndf_fifa = df_fifa.select('short_name','age')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"350205b4-84e8-4451-ab06-5d7534db873c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_fifa.show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a2b356d4-1723-4105-92bc-995a6bfd2e6a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----------------+---+\n|       short_name|age|\n+-----------------+---+\n|         L. Messi| 32|\n|Cristiano Ronaldo| 34|\n|        Neymar Jr| 27|\n|         J. Oblak| 26|\n|        E. Hazard| 28|\n+-----------------+---+\nonly showing top 5 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------------+---+\n|       short_name|age|\n+-----------------+---+\n|         L. Messi| 32|\n|Cristiano Ronaldo| 34|\n|        Neymar Jr| 27|\n|         J. Oblak| 26|\n|        E. Hazard| 28|\n+-----------------+---+\nonly showing top 5 rows\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#Escenario 1\ndf_fifa.withColumn('edad_meses', df_fifa.age * 12).show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c4bd408b-37d8-4390-9d20-2627f7e7d22f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----------------+---+----------+\n|       short_name|age|edad_meses|\n+-----------------+---+----------+\n|         L. Messi| 32|       384|\n|Cristiano Ronaldo| 34|       408|\n|        Neymar Jr| 27|       324|\n|         J. Oblak| 26|       312|\n|        E. Hazard| 28|       336|\n+-----------------+---+----------+\nonly showing top 5 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------------+---+----------+\n|       short_name|age|edad_meses|\n+-----------------+---+----------+\n|         L. Messi| 32|       384|\n|Cristiano Ronaldo| 34|       408|\n|        Neymar Jr| 27|       324|\n|         J. Oblak| 26|       312|\n|        E. Hazard| 28|       336|\n+-----------------+---+----------+\nonly showing top 5 rows\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#Escenario 2\ndf_fifa.withColumn('edad_dias', df_fifa.age * 365)\ndf_fifa.drop('edad_dias')\ndf_fifa.show(5)\n\n#Drop the column “col2”.\n#Print the output of the dataframe."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d972e386-9e15-44e8-bffc-69f32f03755c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----------------+---+\n|       short_name|age|\n+-----------------+---+\n|         L. Messi| 32|\n|Cristiano Ronaldo| 34|\n|        Neymar Jr| 27|\n|         J. Oblak| 26|\n|        E. Hazard| 28|\n+-----------------+---+\nonly showing top 5 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------------+---+\n|       short_name|age|\n+-----------------+---+\n|         L. Messi| 32|\n|Cristiano Ronaldo| 34|\n|        Neymar Jr| 27|\n|         J. Oblak| 26|\n|        E. Hazard| 28|\n+-----------------+---+\nonly showing top 5 rows\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["En el escenario 2 observamos que las ventajas de Spark Lazy. Es decir, Spark se da cuenta de que la creación de col2 no tiene valor e ignora por completo ese paso. Y debido a esta \"pereza\", el trabajo corre más rápido."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3e052d57-74d9-4144-a67d-ebca3d3b9499"}}},{"cell_type":"markdown","source":["## Observemos otro ejemplo"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b0095f02-8889-4428-8794-d38cfbb2f72a"}}},{"cell_type":"code","source":["#1) Creamos una lista\nimport numpy as np\nmy_list = [i for i in range(1,10000000)]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ca470f5-2e35-4ab0-9476-62fefb823fcd"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Creamos un RDD a partir del array de datos\nrdd_data_0 = sc.parallelize(my_list,4)\nprint(\"Número de particiones: \", rdd_data_0.getNumPartitions())\nrdd_data_0"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd0f35f7-98b9-4419-8a2c-e527510d03a8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Número de particiones:  4\nOut[6]: ParallelCollectionRDD[351] at readRDDFromInputStream at PythonRDD.scala:413","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Número de particiones:  4\nOut[6]: ParallelCollectionRDD[351] at readRDDFromInputStream at PythonRDD.scala:413"]}}],"execution_count":0},{"cell_type":"code","source":["# Aplicamos una transformación básica: sumamos 5 a cada elemento del RDD\nrdd_data_1 = rdd_data_0.map(lambda x : x+5) #en este punto Spark, no ha iniciado ninguna transformación, \n                                            #solo registra una serie de transformaciones en la forma linaje RDD.\n# RDD object\nprint(rdd_data_1)\n\n#debugging\nrdd_data_1.toDebugString()  #observando el linaje RDD"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96796a28-96ad-4ea2-b659-ddecbe8ecaf4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"PythonRDD[352] at RDD at PythonRDD.scala:58\nOut[7]: b'(4) PythonRDD[352] at RDD at PythonRDD.scala:58 []\\n |  ParallelCollectionRDD[351] at readRDDFromInputStream at PythonRDD.scala:413 []'","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["PythonRDD[352] at RDD at PythonRDD.scala:58\nOut[7]: b'(4) PythonRDD[352] at RDD at PythonRDD.scala:58 []\\n |  ParallelCollectionRDD[351] at readRDDFromInputStream at PythonRDD.scala:413 []'"]}}],"execution_count":0},{"cell_type":"markdown","source":["Observamos que PythonRDD[352] está conectado a ParallelCollectionRDD[351]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7d4d1a9e-59a3-451c-8b97-4e36b2999d8d"}}},{"cell_type":"code","source":["#Una vez más sumamos valores al RDD\nrdd_data_2 = rdd_data_1.map(lambda x : x+20)\n\n# RDD Object\nprint(rdd_data_2)\n\n# Conseguimos el linaje\nprint(rdd_data_2.toDebugString())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8cf11088-3709-4050-86ed-625aee4c97e2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"PythonRDD[353] at RDD at PythonRDD.scala:58\nb'(4) PythonRDD[353] at RDD at PythonRDD.scala:58 []\\n |  ParallelCollectionRDD[351] at readRDDFromInputStream at PythonRDD.scala:413 []'\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["PythonRDD[353] at RDD at PythonRDD.scala:58\nb'(4) PythonRDD[353] at RDD at PythonRDD.scala:58 []\\n |  ParallelCollectionRDD[351] at readRDDFromInputStream at PythonRDD.scala:413 []'\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["Observamos que PythonRDD[353] está conectado a ParallelCollectionRDD[351].\nPodemos ver que automáticamente se ha saltado un paso redundante y agregará 25 en un solo paso en lugar de cómo lo definimos. Entonces, Spark define automáticamente la mejor ruta para realizar cualquier acción y solo realiza las transformaciones cuando es necesario."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b656fe05-4937-49cd-9ce1-5446cc4a17ee"}}},{"cell_type":"markdown","source":["### Ventajas de la evaluación \"lazy\"\n- Reduce la complejidad: Las dos complejidades principales de cualquier operación son el tiempo y del espacio. Usando la evaluación perezosa de Apache Spark podemos superar ambos. Como no ejecutamos todas las operaciones, por lo tanto, se ahorra tiempo. Nos permite trabajar con una estructura de datos infinita. La acción se activa solo cuando se requieren los datos, reduce la sobrecarga.\n\n- Optimización de recursos: la optimización se logra a através de reducir el número de recursos a emplear.\n\n- Ahorro de cómputo e incrementa la velocidad: la evaluación perezosa juega un papel clave en el ahorro de gastos generales de cálculo. Dado que solo los valores necesarios se computan. Ahorra el viaje entre el conductor y el grupo, por lo que acelera el proceso."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8700c5bf-0fb8-4035-9af9-d42a8a310a60"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"lazy_evaluation","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3827491274431600}},"nbformat":4,"nbformat_minor":0}
